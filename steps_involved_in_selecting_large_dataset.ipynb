{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91388d88-765e-4fc0-aeab-04b1cd0b453d",
   "metadata": {},
   "source": [
    "# Steps Involved in Selecting a Model For a larger Dataset\n",
    "\n",
    "In my article on the [Steps Involved in Selecting a Model](#). I talked about the difference between small and large datasets in relation to model selection. I also talked about how to perform model selection and evaluation on them. This notebook address means to select a model on a larger dataset. \n",
    "\n",
    "The dataset we'll be making use of will be the [House Prices - Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) dataset. It isn't so large a dataset itself, but it will be a perfect example. The measures I describe from my article includes:\n",
    "\n",
    "1. Transform Categorical Columns to Numeric (If any)\n",
    "2. Scale Continuous Columns (if necessary)\n",
    "3. Split the Dataset\n",
    "4. Elect Candidate Model\n",
    "5. Perform Model Evaluation\n",
    "6. Model Selection\n",
    "\n",
    "I already worked with this dataset at one point. So, I would create a function to clean up and prepare the dataset so we can move on to the third step. The code for the Exploratory Data Analysis (EDA), Data Cleaning and Transformation can be found on my Kaggle page at  [House Prices Prediction (Beginner)](https://www.kaggle.com/ganiyuolalekan/house-prices-prediction-beginner/notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d575bd4-5353-4942-93f3-02340c4e1fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3b9ae3f-8318-4edb-9f66-26c70aba21f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "Id                                                                    \n",
       "1           60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "2           20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "3           60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "4           70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "5           60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "   LandContour Utilities LotConfig  ... PoolArea PoolQC Fence MiscFeature  \\\n",
       "Id                                  ...                                     \n",
       "1          Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
       "2          Lvl    AllPub       FR2  ...        0    NaN   NaN         NaN   \n",
       "3          Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
       "4          Lvl    AllPub    Corner  ...        0    NaN   NaN         NaN   \n",
       "5          Lvl    AllPub       FR2  ...        0    NaN   NaN         NaN   \n",
       "\n",
       "   MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "Id                                                             \n",
       "1        0      2    2008        WD         Normal     208500  \n",
       "2        0      5    2007        WD         Normal     181500  \n",
       "3        0      9    2008        WD         Normal     223500  \n",
       "4        0      2    2006        WD        Abnorml     140000  \n",
       "5        0     12    2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data/house_prices/train.csv\", index_col='Id')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beb73e80-8fc7-4350-bf8f-3026a7d3e0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 80)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef1f7905-d8c4-464c-832f-19b7f8f12365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1460 entries, 1 to 1460\n",
      "Data columns (total 80 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MSSubClass     1460 non-null   int64  \n",
      " 1   MSZoning       1460 non-null   object \n",
      " 2   LotFrontage    1201 non-null   float64\n",
      " 3   LotArea        1460 non-null   int64  \n",
      " 4   Street         1460 non-null   object \n",
      " 5   Alley          91 non-null     object \n",
      " 6   LotShape       1460 non-null   object \n",
      " 7   LandContour    1460 non-null   object \n",
      " 8   Utilities      1460 non-null   object \n",
      " 9   LotConfig      1460 non-null   object \n",
      " 10  LandSlope      1460 non-null   object \n",
      " 11  Neighborhood   1460 non-null   object \n",
      " 12  Condition1     1460 non-null   object \n",
      " 13  Condition2     1460 non-null   object \n",
      " 14  BldgType       1460 non-null   object \n",
      " 15  HouseStyle     1460 non-null   object \n",
      " 16  OverallQual    1460 non-null   int64  \n",
      " 17  OverallCond    1460 non-null   int64  \n",
      " 18  YearBuilt      1460 non-null   int64  \n",
      " 19  YearRemodAdd   1460 non-null   int64  \n",
      " 20  RoofStyle      1460 non-null   object \n",
      " 21  RoofMatl       1460 non-null   object \n",
      " 22  Exterior1st    1460 non-null   object \n",
      " 23  Exterior2nd    1460 non-null   object \n",
      " 24  MasVnrType     1452 non-null   object \n",
      " 25  MasVnrArea     1452 non-null   float64\n",
      " 26  ExterQual      1460 non-null   object \n",
      " 27  ExterCond      1460 non-null   object \n",
      " 28  Foundation     1460 non-null   object \n",
      " 29  BsmtQual       1423 non-null   object \n",
      " 30  BsmtCond       1423 non-null   object \n",
      " 31  BsmtExposure   1422 non-null   object \n",
      " 32  BsmtFinType1   1423 non-null   object \n",
      " 33  BsmtFinSF1     1460 non-null   int64  \n",
      " 34  BsmtFinType2   1422 non-null   object \n",
      " 35  BsmtFinSF2     1460 non-null   int64  \n",
      " 36  BsmtUnfSF      1460 non-null   int64  \n",
      " 37  TotalBsmtSF    1460 non-null   int64  \n",
      " 38  Heating        1460 non-null   object \n",
      " 39  HeatingQC      1460 non-null   object \n",
      " 40  CentralAir     1460 non-null   object \n",
      " 41  Electrical     1459 non-null   object \n",
      " 42  1stFlrSF       1460 non-null   int64  \n",
      " 43  2ndFlrSF       1460 non-null   int64  \n",
      " 44  LowQualFinSF   1460 non-null   int64  \n",
      " 45  GrLivArea      1460 non-null   int64  \n",
      " 46  BsmtFullBath   1460 non-null   int64  \n",
      " 47  BsmtHalfBath   1460 non-null   int64  \n",
      " 48  FullBath       1460 non-null   int64  \n",
      " 49  HalfBath       1460 non-null   int64  \n",
      " 50  BedroomAbvGr   1460 non-null   int64  \n",
      " 51  KitchenAbvGr   1460 non-null   int64  \n",
      " 52  KitchenQual    1460 non-null   object \n",
      " 53  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 54  Functional     1460 non-null   object \n",
      " 55  Fireplaces     1460 non-null   int64  \n",
      " 56  FireplaceQu    770 non-null    object \n",
      " 57  GarageType     1379 non-null   object \n",
      " 58  GarageYrBlt    1379 non-null   float64\n",
      " 59  GarageFinish   1379 non-null   object \n",
      " 60  GarageCars     1460 non-null   int64  \n",
      " 61  GarageArea     1460 non-null   int64  \n",
      " 62  GarageQual     1379 non-null   object \n",
      " 63  GarageCond     1379 non-null   object \n",
      " 64  PavedDrive     1460 non-null   object \n",
      " 65  WoodDeckSF     1460 non-null   int64  \n",
      " 66  OpenPorchSF    1460 non-null   int64  \n",
      " 67  EnclosedPorch  1460 non-null   int64  \n",
      " 68  3SsnPorch      1460 non-null   int64  \n",
      " 69  ScreenPorch    1460 non-null   int64  \n",
      " 70  PoolArea       1460 non-null   int64  \n",
      " 71  PoolQC         7 non-null      object \n",
      " 72  Fence          281 non-null    object \n",
      " 73  MiscFeature    54 non-null     object \n",
      " 74  MiscVal        1460 non-null   int64  \n",
      " 75  MoSold         1460 non-null   int64  \n",
      " 76  YrSold         1460 non-null   int64  \n",
      " 77  SaleType       1460 non-null   object \n",
      " 78  SaleCondition  1460 non-null   object \n",
      " 79  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(34), object(43)\n",
      "memory usage: 923.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fb9dfb3-41b3-4b15-b685-b203ffeb3f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_house_price_dataset(data):\n",
    "    \"\"\"\n",
    "    Cleans and transform the dataset. Details at:\n",
    "    https://www.kaggle.com/ganiyuolalekan/house-prices-prediction-beginner/notebook\n",
    "    \"\"\"\n",
    "    \n",
    "    target = data[\"SalePrice\"].to_numpy()\n",
    "    \n",
    "    data.drop([\n",
    "        \"Alley\", \"FireplaceQu\", \"PoolQC\", \"Fence\", \"MiscFeature\", \"SalePrice\"\n",
    "    ], axis=1, inplace=True)\n",
    "    \n",
    "    continuous_col= list(data.describe().columns)\n",
    "    \n",
    "    categorical_col = [\n",
    "        col \n",
    "        for col in data.columns \n",
    "        if col not in continuous_col\n",
    "    ]\n",
    "    \n",
    "    continuous_data_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('num_scaler', StandardScaler()),\n",
    "    ])\n",
    "    \n",
    "    categorical_data_pipeline = Pipeline([\n",
    "        ('freq_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('cat_encoder', OrdinalEncoder())\n",
    "    ])\n",
    "    \n",
    "    housing_price_pipeline = ColumnTransformer([\n",
    "        (\"continous\", continuous_data_pipeline, continuous_col),\n",
    "        (\"categorical\", categorical_data_pipeline, categorical_col),\n",
    "    ])\n",
    "    \n",
    "    transformed_dataset = housing_price_pipeline.fit_transform(data)\n",
    "    \n",
    "    dataset.loc[:, list(dataset.columns)] = transformed_dataset\n",
    "    \n",
    "    return target, transformed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc86bea4-e6ea-4b1e-a62b-af66125335ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "target, transformed_dataset = clean_house_price_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25e2e08e-9a77-4b94-86f0-d5c9f22f2083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 74), numpy.ndarray, (1460,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_dataset.shape, type(transformed_dataset), target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c01d24-cf91-453a-a077-8905ab29fd79",
   "metadata": {},
   "source": [
    "With the `clean_house_price_dataset` function, we’ll be able to clean and transform the dataset. we can then proceed to split the dataset and evaluate the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf12844-7deb-44d1-8b1a-b55afcaf4692",
   "metadata": {},
   "source": [
    "### Split the Data-set\n",
    "\n",
    "The reason we perform an evaluation on machine learning (ML) models is to ensure they don't under-fit or over-fit.\n",
    "\n",
    "We were able to evaluate the iris data-set (a small data-set) using cross-validation, but given our data-set isn't as small, validating naively would be computationally expensive.\n",
    "\n",
    "Therefore, we have to split the dataset into a train and test set. Given the entire dataset has a shape of `(1460, 80)`, and `(1460, 74)` after cleaning and transformation, we can perform cross-evaluation on the train-set and evaluate our model performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed2dd85d-438c-44c7-97da-3c7c93b429b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92868cde-074e-4ba2-ae51-51fedcf0162c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022, 438)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1460 - (1460 * .3)), round(1460 * .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf6c4267-a9ce-4ed9-ae06-340e634d84c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 74), (438, 74), (1022,), (438,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(transformed_dataset, target, test_size=.3, shuffle=True, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec798e35-c134-4f80-a4b5-6f383c7709b4",
   "metadata": {},
   "source": [
    "### Elect Candidate Model\n",
    "\n",
    "Now that we've perfectly split the dataset into both train and test sets, we then proceed to elect models that can solve this task.\n",
    "\n",
    "We have to understand the dataset. I talked about it in my notebook [House Prices Prediction (Beginner)](https://www.kaggle.com/ganiyuolalekan/house-prices-prediction-beginner/notebook) where I gave an [overview of the dataset](https://www.kaggle.com/ganiyuolalekan/house-prices-prediction-beginner#2.1.-Overview-of-the-data).\n",
    "\n",
    "So, we're dealing with a regression task consisting of lots of categorical features, having models with linear and decision-making abilities would be useful, like the Decision Tree Regressor or Random Forest Regressor. But let's go for the Random Forest Regressor since it’s more of an ensemble of Decision Trees.\n",
    "\n",
    "We should also pick models like Support Vector Regressor, Linear Regression, and K-Neighbors Regressor since we're performing evaluations.\n",
    "\n",
    "> The XGBoost will prove to be a very vital tool in your ML journey and I suggest examining its usage in the notebook [XGBoost](https://www.kaggle.com/dansbecker/xgboost) by Kaggle grandmaster [Dans Becker](https://www.kaggle.com/dansbecker). More resources on XGBoost in the **further reading** section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e00bd58d-b9fd-4c63-a1b2-cc7e1d31f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"Linear Regression\",\n",
    "    \"K-Neighbors Regressor\",\n",
    "    \"Support Vector Regressor\",\n",
    "    \"Random Forest Regressor\"\n",
    "]\n",
    "\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    KNeighborsRegressor(),\n",
    "    SVR(),\n",
    "    RandomForestRegressor()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd92d66e-67c1-4279-9725-3b397cfe5095",
   "metadata": {},
   "source": [
    "### Perform Model Evaluation\n",
    "\n",
    "Now that we've successfully split our dataset, and elected the models we want to use. It's time to see how the individual models perform on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47111d75-93e0-4c93-9105-aff1571e6d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(data, target, names_models):\n",
    "    \"\"\"\n",
    "    Performing model comparision my anallyzing the different models\n",
    "    along with their performance.\n",
    "    \"\"\"\n",
    "    \n",
    "    record = {}\n",
    "    \n",
    "    avg_model_performance = []\n",
    "    \n",
    "    for name, model in zip(\n",
    "        names_models.keys(), names_models.values()\n",
    "    ):\n",
    "        model.fit(data, target)\n",
    "        predictions = model.predict(data)\n",
    "        \n",
    "        model_mse = mean_squared_error(target, predictions)\n",
    "        model_mae = mean_absolute_error(target, predictions)\n",
    "        \n",
    "        model_record = {\n",
    "            \"model\": name,\n",
    "            \"mean_squared_error\": model_mse,\n",
    "            \"mean_absolute_error\": model_mae,\n",
    "        }\n",
    "        \n",
    "        record[name] = model_record\n",
    "        \n",
    "        avg_model_performance.append((round(model_mae, 2), name))\n",
    "    \n",
    "    record['Model Performance Rating'] = sorted(avg_model_performance)\n",
    "    \n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93f9fddb-60cf-44d2-bb76-482dc77d0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = compare_models(\n",
    "    X_train, y_train, \n",
    "    {\n",
    "        name: model\n",
    "        for name, model in zip(names, models)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a5e32e5-e2e1-4dd7-8485-4fae9083a665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'Linear Regression', 'mean_squared_error': 947208848.3487878, 'mean_absolute_error': 18860.18959703269}\n",
      "{'model': 'K-Neighbors Regressor', 'mean_squared_error': 1116571996.207319, 'mean_absolute_error': 20864.65264187867}\n",
      "{'model': 'Support Vector Regressor', 'mean_squared_error': 6282322967.635323, 'mean_absolute_error': 54896.07183847585}\n",
      "{'model': 'Random Forest Regressor', 'mean_squared_error': 136855332.17973176, 'mean_absolute_error': 6791.2177201565555}\n"
     ]
    }
   ],
   "source": [
    "for name in names:\n",
    "    print(record[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb32c8a8-5069-4a1a-a80c-72319dd85201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6791.22, 'Random Forest Regressor'),\n",
       " (18860.19, 'Linear Regression'),\n",
       " (20864.65, 'K-Neighbors Regressor'),\n",
       " (54896.07, 'Support Vector Regressor')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record['Model Performance Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d52612e-38ed-4fcd-a9c8-f59f71aee2cc",
   "metadata": {},
   "source": [
    "Beyond doubt, the Random Forest Regressor performed best, outperforming the Linear Regression model approx 3x. Although since our focus is on model selection I avoided cross-validating and fine-tuning the models.\n",
    " \n",
    "> In most cases, I would fine-tune and cross-validate the model (using grid search) while searching out the best accuracy each model can produce before making a decision. But the model’s default parameters are also decent enough for this task. So let's leave it simple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc46b8-f368-4ba5-92ba-8b0bc92980e0",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "\n",
    "After splitting the dataset, electing the candidate model, and performing model evaluation we can come to the conclusion that the Random Forest Regressor will be best suited for deployment having a mean absolute error (MAE) of 6732.92.\n",
    "\n",
    "Although we didn't quite fine-tune the model. We can get a much better MAE by fine-tuning the Random Forest Regressor, but the point has been established.\n",
    "\n",
    "> You could try out the XGBoost and compare it to see if it performs better. What if you fine-tune the XGBoost model as well!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663357d0-ca31-4251-8fd5-765fcb3e0110",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The larger the dataset the more accurate your model will become, the more the possibility, the more the computing power needed and the more the complication.\n",
    "\n",
    "With a smaller dataset though, the process of splitting the dataset won't be essential as smaller datasets can’t be processed naively and thus the need for cross-validating smaller sets with a predefined number of folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951af41c-ad5f-4103-8f72-73db78797991",
   "metadata": {},
   "source": [
    "### Further Reading\n",
    "\n",
    "Data Cleaning\n",
    "\n",
    "- [The Ultimate Guide to Data Cleaning](https://towardsdatascience.com/the-ultimate-guide-to-data-cleaning-3969843991d4)\n",
    "- [Data Cleaning with Python and Pandas](https://towardsdatascience.com/data-cleaning-with-python-and-pandas-detecting-missing-values-3e9c6ebcf78b)\n",
    "\n",
    "Encoding Categorical Columns\n",
    "\n",
    "- [Encoding Categorical data in Machine Learning](https://medium.com/bycodegarage/encoding-categorical-data-in-machine-learning-def03ccfbf40)\n",
    "- [Guide to Encoding Categorical Features Using Scikit-Learn For Machine Learning](https://towardsdatascience.com/guide-to-encoding-categorical-features-using-scikit-learn-for-machine-learning-5048997a5c79)\n",
    "\n",
    "Scikit-Learn Models\n",
    "\n",
    "- [Support Vector Machine](https://en.wikipedia.org/wiki/Support-vector_machine)\n",
    "- [Random Forest](https://en.wikipedia.org/wiki/Random_forest)\n",
    "- [K-Nearest Neighbor](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)\n",
    "- [Linear Regression](https://en.wikipedia.org/wiki/Linear_regression)\n",
    "\n",
    "Further Reading On Model Selection\n",
    "\n",
    "- [A “short” introduction to model selection](https://towardsdatascience.com/a-short-introduction-to-model-selection-bb1bb9c73376)\n",
    "- [A Gentle Introduction to Model Selection for Machine Learning](https://machinelearningmastery.com/a-gentle-introduction-to-model-selection-for-machine-learning/)\n",
    "\n",
    "Associated Notebooks\n",
    "\n",
    "- [Steps Involved in Selecting a Model For a Small Data-set](https://www.kaggle.com/ganiyuolalekan/model-selection-for-small-dataset)\n",
    "\n",
    "Book\n",
    "\n",
    "- [Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b24b56-9766-4257-b159-48bd402a8086",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
